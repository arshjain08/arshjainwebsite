{
  "posts": [
    {
      "id": "langchain-ambient-agents",
      "title": "Langchain and Ambient Agents",
      "excerpt": "Exploring LangChain's newest framework around ambient agents - AI that sits in the background, ready to act when something happens.",
      "content": "Last summer, during my internship at SLB, I got to use LangChain and LangGraph to build part of an open-source Retrieval-Augmented Generation tool. What struck me at the time was that just as important as the models themselves is the infrastructure that enables them. A good model is only half the story. The real challenge is building the scaffolding that connects models to data, user intent, and feedback loops in a way that is reliable. Without that infrastructure, even the strongest model feels like a demo rather than a tool.\n\nFast forward to this summer, I was lucky enough to get invited to LangGraph's office to see them present one of their newest frameworks around ambient agents. The idea is simple but powerful: instead of agents you call on for a single task, ambient agents are always on, sitting in the background and ready to act when something happens. In the presentation they described them as event-triggered and asynchronous, meaning they do not just wait for you to type a prompt, but can respond to things like a new commit, a failed test, or even just a calendar event.\n\nThe architecture that makes this possible is what stuck with me. Instead of chaining everything together in brittle, hard-coded flows, these agents operate more like decision-makers. They are built to summarize, handle errors explicitly, and know when to stop chasing an unhelpful path. That last part might sound small, but anyone who has tried to get an LLM to do multi-step reasoning knows how easy it is for the model to spiral down a rabbit hole. By giving agents a way to recognize and recover from failure states, the system feels more trustworthy.\n\nOne of the demos they showed was Open SWE, basically an ambient coding agent. It hooks into the development workflow and can be triggered automatically by events in a repo. Imagine pushing a commit and instead of just seeing a red X, the agent kicks off in the background, digs into the logs, and gives you a summary of what failed along with a suggested fix. That is a huge shift from the current model where you have to stop everything, parse through error messages, and then go hunting for the cause yourself.\n\nTechnically, the \"always active\" part requires a lot of careful orchestration. You need background processes that can run asynchronously without hogging resources, you need a system for catching errors gracefully, and you need to prevent agents from endlessly looping. They emphasized that summarization is one of the hardest parts. Turning raw logs, diffs, or user actions into something a human can act on is not trivial. But it is also the piece that makes this feel less like automation and more like collaboration.\n\nThinking about the future, I could see this moving AI away from being a tool you explicitly open and toward being a layer that is just there, woven into whatever you are doing. In software engineering, that could mean agents that quietly track your workflow, run checks in the background, and surface issues before you even notice them. In other domains, it could mean financial dashboards that summarize market shifts the moment they happen, or productivity tools that flag patterns in your day without you having to ask.\n\nThe big picture is that ambient agents flip the interaction model. Instead of you always going to the AI, the AI comes to you when it has something useful to say. That requires trust, good design, and a lot of invisible infrastructure. But if it works, it changes how we think about human attention. We could spend less time managing noise and more time making actual decisions.\n\nThanks to LangChain for inviting me to see the talk and for building such a cool tool! It was inspiring to get a glimpse of what they are working on, and I truly believe these types of agents are the way that LLMs can genuinely change the way we work and even live.",
      "date": "2025-07-17",
      "category": "technical",
      "tags": ["AI", "LangChain", "Agents", "Technology", "Development"],
      "readTime": "8 min read",
      "featured": true,
      "image": "/images/blog/langchainphoto.JPG"
    },
    {
      "id": "crypto-coinbase-summer",
      "title": "Thoughts on Crypto after Summer at Coinbase",
      "excerpt": "Reflecting on my perspective shift on cryptocurrency and blockchain after spending a summer at Coinbase, from skeptic to believer.",
      "content": "Honestly, before working at Coinbase this past summer I was not super into the crypto space. But this summer, I jumped into the entire environment, meeting friends and coworkers who have been in this space for a while. I went to blockchain events, hackathons, and just a bunch of things that taught me a lot about bitcoin, crypto, and the broader ecosystem.\n\nLet's start where bitcoin itself started, Satoshi Nakamoto's white paper. I first read it while preparing for my interviews with Coinbase, and I was surprised by how elegant the solution of a decentralized yet secure currency is. The white paper is only nine pages long, but it lays out a system that could change how the world thinks about money.\n\nWhat makes bitcoin so interesting to me is the underlying technology. At its core, the blockchain is a distributed ledger that anyone can verify but no one can control. That combination of transparency and decentralization allows for solutions that were not possible before. One area where this shines is cross-border payments. Sending money across countries is still expensive and slow with banks, but with crypto it can be close to instant.\n\nThis is where stablecoins come into play. They take the volatility of bitcoin and other cryptocurrencies out of the picture by pegging the value to something like the US dollar. That makes them incredibly useful for remittances, which I actually did a research paper on when I was studying abroad in Dublin for my international macroeconomics class.\n\nOne funny example from my own life this summer is that my Canadian roommate paid me rent in USDC because he had a limit on how much USD cash he could withdraw. That single transaction showed me how crypto can create real-world utility. It also gave me a glimpse of what financial freedom could look like. Imagine a society where access to money is free and borderless, where anyone can participate in the global economy no matter where they are from. That vision lines up pretty well with Coinbase's mission.\n\nSomething else I find fascinating is the idea of tokenized stocks on the blockchain. Imagine being able to trade shares of Apple or Tesla twenty-four hours a day, seven days a week, with transactions clearing instantly on the blockchain. That could fundamentally reshape how people invest.\n\nNow, with all of that said, there are still some real problems with crypto as it exists today. A lot of the technology is too technical and intimidating. Gas fees, bridging, staking, wallets—these are terms that most people do not want to learn. Ideally, all of this should be abstracted away. Think about how people use Venmo today. They do not need to understand ACH transfers or bank settlement systems. Imagine an international version of Venmo that is powered by crypto and stablecoins, but where the user never has to know it is crypto under the hood. That is the kind of product that could make mass adoption possible.\n\nRight now crypto feels like it has two competing sides: the investment side and the currency side. The investment side has taken off, but the currency side has lagged. Personally, I would love to see the currency side get more attention, because that is where I think the most transformative change could happen.\n\nCrypto also has a stigma to overcome. A lot of people see it as risky, scam-filled, or only for speculators. For adoption to grow, the space has to build trust. That means better regulation, consumer protection, and legislation. The recently passed GENIUS Act is a step in that direction, helping to create guardrails while also giving the industry some legitimacy in the eyes of the public.\n\nOverall, this summer made me much more optimistic about what crypto can be, but also more realistic about the challenges ahead. The technology is powerful, but it needs to become invisible to the user. If that happens, then maybe the vision of global financial freedom has a chance of becoming real.",
      "date": "2025-08-17",
      "category": "personal",
      "tags": ["Cryptocurrency", "Coinbase", "Finance", "Blockchain", "Career"],
      "readTime": "7 min read",
      "featured": true,
      "image": "/images/blog/crypto.jpg"
    },
    {
      "id": "smart-glasses-mentra-hackathon",
      "title": "Thoughts of Smart Glasses and My Time at the Mentra Hackathon",
      "excerpt": "Building PricePal at the Mentra Live Smart Glasses Hackathon at YC headquarters, and reflections on the future of AR technology.",
      "content": "After doing the MARA hackathon with my roommate Cole Dermott and his friend back at college William Wang, we wanted to do some more hackathons! We saw on Luma:\n\n\"Join us for the Mentra Live Smart Glasses Hackathon, hosted at the Y Combinator headquarters in San Francisco! We're gathering 100 talented hackers and developers, pairing each with a Mentra Live pre-release camera smartglasses, and unleashing creativity, innovation, and imagination.\"\n\nWe had to go. A chance to go to YC headquarters and we get to develop on smart glasses! So we all applied to the hackathon, and we all got in! I've worked a little bit on VR when I helped out our district's middle school VR development program during my senior year of high school, but I had never developed or even used AR smart glasses. I always thought the technology was cool, but never had the chance to have them. We came in with a team, so all we had to do was come up with an idea and execute.\n\n## The Idea\n\nThe idea for our project, PricePal, actually came from a pretty ordinary moment. A while back, I was in Best Buy staring at a WiFi adapter for $40. Out of curiosity, I checked Amazon on my phone and saw the exact same product for $15. I had almost wasted $25 just because I didn't stop to look. That stuck with me, and when we sat down to brainstorm at the hackathon it clicked. What if you could look at any product through your glasses, ask whether it was a good price, and get the answer right away?\n\nThat's what we built. PricePal turns Mentra glasses into a personal shopping assistant. You look at something, ask \"Hey Mentra, is this a good price?\" and it tells you if you're getting ripped off or if the deal is worth it. We stitched it together using Mentra's camera and microphone APIs, ElevenLabs for voice generation, and Gemini's grounded search to pull live prices from online retailers and for computer vision support. The glasses could then talk back with a simple answer or show the comparison right in the display.\n\nThe issue that we ran into was that they had two glasses. One with a camera and a speaker, and one with a screen and speaker. This was frustrating as we envisioned a product where we wouldn't need anything else, just your glasses and whatever product was in front of you. We ended up choosing the one with a camera and a speaker, as that is essential for our product, and ended up relying a lot on the speaker for voice output and if you wanted more detail, we had an entire UI on the phone to show more details about the product you were looking at.\n\nBuilding it in under 24 hours was equal parts exciting and chaotic. Mentra's APIs were brand new, so we were figuring things out as we went. We hacked together a voice activation flow, built a pipeline to send images off for recognition, and layered in the price search and comparison. At one point we even managed to deploy a live version during the hackathon using Vercel, which felt risky but paid off in the demo.\n\nThe best part was running through scenarios in real time. At Best Buy: \"Hey PricePal, is this USB adapter a good price?\" and hearing the glasses respond that it was cheaper on Amazon. Or holding up Meta's Ray-Ban glasses and having PricePal point out that the Mentra ones were over a hundred dollars less with more flexibility. Every time it worked, people around us were surprised at how natural it felt.\n\nThey ended up posting our project to our project to their x account, and it was super cool to see all of the interactions and comments of people genuinely seeing how useful this could be! (I am in the video I swear look at the last few seconds haha)\n\nhttps://x.com/caydengineer/status/1949509327066472453\n\nLooking back, the biggest takeaway wasn't just that we made something that worked. It was seeing how fast an idea that feels like a consumer fantasy—never overpaying again—can actually come to life when you're forced to ship in a weekend. And on top of that, it was just plain fun to hack on pre-release AR hardware at YC, surrounded by people trying to figure out what the future of this tech might look like.\n\n## My Opinions on the Tech\n\nBecause a lot of this tech was pre-release, there were lots of small things we had to get around, but overall, the tech was pretty alright. Before deciding on our idea, we were trying out both the camera glasses and the screen glasses, and the screen showed only green text, which I was kind of surprised by but it makes lots of sense. I see lots of applications for helping people with disabilities like those who are hard of hearing, or maybe for directions without having to look down at your phone.\n\nMaybe smartglasses will lead to a world which ironically would lead to less people looking at a screen. I mean you will have one on your face, but often I pick up my phone to do an essential task, and end up getting distracted by Instagram or Reddit or whatever app is vying for my attention. In a world of smart glasses, I can send messages, hear notifications, and do everything just with a quick voice prompt.\n\nOverall, this tech is super cool and I do see a future for it, but there is still lots of improvement that needs to be made before these are mainstream. Big thanks to Mentra for putting on the event, and to Cole and William for building PricePal with me!",
      "date": "2025-07-14",
      "category": "technical",
      "tags": ["AR", "Smart Glasses", "Hackathon", "Technology", "YC"],
      "readTime": "6 min read",
      "featured": false,
      "image": "/images/blog/mentra.jpg"
    },
    {
      "id": "bitcoin-ai-mara-hackathon",
      "title": "Hacking Bitcoin with AI at the MARA Hackathon",
      "excerpt": "Building WattsonAI at the MARA hackathon - an AI assistant for mining operations that won us a bitcoin miner and best design award.",
      "content": "TLDR: I won a hackathon and am a partial owner of a bitcoin miner.\n\nWhen I first got to San Francisco, I knew about the whole stereotype of hackathons and \"tech bros,\" but the only ones I'd done before were at Rice. Those were fun, but let's be honest — the competition was mostly just other Rice students and maybe a few from UH. My roommate, on the other hand, was from Waterloo and had done more hackathons than I could count, especially in the crypto space.\n\nOne night, we came across this hackathon hosted by MARA: 100 hackers, 8 hours, and the prize was literally 1 Bitcoin (about $120k at the time). Split between us, that'd be 60k each. It sounded way too wild to pass up. We both submitted our résumés and LinkedIns, brought in another friend of his who was also ridiculously talented, and somehow all of us got in.\n\nEven though I was interning at Coinbase that summer, I wasn't really in the \"crypto world.\" I was on the AI/ML side, working on risk models — as far away from Bitcoin mining as you can get. So I figured this was my chance to dive in headfirst.\n\n## The Idea\n\nThey gave us access to an API with mining allocation data, and at first we weren't totally sure what to do with it. After bouncing ideas around, we thought: what if we built an AI assistant for mining ops? Something that could look at all the energy prices, hash rates, and profitability stuff in real time, and then actually tell you what to do with it.\n\nWe didn't just want to make another dashboard with charts. We wanted it to feel like you had a smart co-pilot — one that could highlight risks, make suggestions, and answer questions in plain English. So that became WattsonAI.\n\nOf course, this wasn't a straight shot. We spent a lot of time iterating with the judges on what would actually be useful vs. what was just hackathon glitter. Some of our early ideas got scrapped, some evolved, and the final design was really shaped by those conversations.\n\nAnd somewhere along the way, we got a little too obsessed with the \"liquid glass\" effect in the UI. Every time we showed progress, we'd be like, \"Okay but hear us out… what if we add more liquid glass?\" By the end, I think we were 50% building an AI system and 50% just trying to justify sneaking liquid glass into every corner of the app.\n\nI have done many projects before, but shipping this fast requires lots of tools. Shout out to Claude Code and Cursor, as even though they weren't perfect at all, they provided lots of help in creating the building blocks for the UI and general structure of the code, so we skipped a lot of the tedious repetitive parts of building a website like this. Also Vercel was extremely useful for deploying websites super easily, I'm pretty sure we just attached our github, added the API keys, and vercel took care of everything else, so we actually deployed our website live during the hackathon, which really stood us apart.\n\nAfter the initial presentations, we stood in anticipation waiting for the top 5 teams to be announced. We visited the Founders, Inc. office because it was right next door, and one of the employees just showed us around which was really cool!\n\nThen they started announcing the top 5 teams for the prize of 1 bitcoin. They listed out 3 numbers, none of which were ours. Then, we heard our number \"team 75\", the excitement was brewing. We had 20 minutes to ensure our presentation was solid, and essentially 110,000 dollars was on the line. We cooked something up, and finally it was our turn. It was honestly a blur to me, all I remember was talking and showing the features, and then the whole room turning to applause.\n\nThe award ceremony was right after. Did we win? Did we get anything? They advertised the only award was 1 bitcoin, so I was surprised when they said there were other prizes, but then we found out we won best design, which we were happy about, but when we walked back, they said we won a miner???\n\nYea, we won a $3000 dollar bitcoin miner, where we are currently earning around $15 a day minus electricity. We talked to the judges and we found out it was between our team and another team for the 1 bitcoin grand prize, which was tough, but it honestly taught me so much, and was such a fun experience!\n\nThanks to MARA for organizing such a fun hackathon, and my teammates Cole Dermott and William Wang!\n\nHere is the video of the project in action!: https://www.youtube.com/watch?v=XDzWh5-onb0&ab_channel=WilliamW.\n\nAlso if you want to check out the UI, the project is live at https://wattson-ai.vercel.app/config . Keep in mind, the MARA api isn't fully working post-hackathon so some functionalities aren't up and running, but I am still very proud of the UI and design of the general website, as well as all the features we were able to put in it in such a short period of time :)",
      "date": "2025-06-14",
      "category": "technical",
      "tags": ["Bitcoin", "AI", "Hackathon", "Mining", "Crypto"],
      "readTime": "5 min read",
      "featured": true,
      "image": "/images/blog/mara.jpg"
    }
  ],
  "categories": [
    {
      "id": "technical",
      "name": "Technical",
      "description": "Deep dives into technology, programming, and engineering topics"
    },
    {
      "id": "personal",
      "name": "Personal",
      "description": "Life reflections, experiences, and personal growth stories"
    }
  ]
}